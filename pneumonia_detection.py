# -*- coding: utf-8 -*-
"""pneumonia_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C93LIM0sA9zovlA58fwaMtqPC-1FoPVn
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia/

import zipfile
zip_ref = zipfile.ZipFile('/content/chest-xray-pneumonia.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2, os, random
import plotly.express as px
import glob
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix, roc_auc_score

# Data Preprocessing
base_dir = '/content/chest_xray'
train_dir = os.path.join(base_dir, 'train')
val_dir = os.path.join(base_dir, 'val')
test_dir = os.path.join(base_dir, 'test')

normal_lung_image = load_img("/content/chest_xray/test/NORMAL/IM-0001-0001.jpeg")
print("NORMAL")
plt.imshow(normal_lung_image)
plt.show()

pneumonia_lung_image = load_img("/content/chest_xray/test/PNEUMONIA/person109_bacteria_527.jpeg")
print("PNEUMONIA")
plt.imshow(normal_lung_image)
plt.show()

# Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

train_set = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

val_set = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

test_set = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode='binary'
)

# Model Development
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Model Training
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(
    train_set,
    validation_data=val_set,
    epochs=20,
    callbacks=[early_stopping]
)

# Model Evaluation
plt.figure(figsize=(10, 5))
plt.title("Model Accuracy")
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.show()

plt.figure(figsize=(10, 5))
plt.title("Model Loss")
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.show()

# Evaluate model on the test set
test_loss, test_accuracy = model.evaluate(test_set)
print("Test Accuracy: {:.2f}%".format(test_accuracy * 100))
print("Test Loss: {:.2f}".format(test_loss))

# Calculate sensitivity, specificity, and ROC-AUC
predictions = (model.predict(test_set) > 0.5).astype(int)
y_true = test_set.classes

conf_matrix = confusion_matrix(y_true, predictions)
print("Confusion Matrix:\n", conf_matrix)

tp = conf_matrix[1, 1]
fn = conf_matrix[1, 0]
fp = conf_matrix[0, 1]
tn = conf_matrix[0, 0]

sensitivity = tp / (tp + fn)
specificity = tn / (tn + fp)
roc_auc = roc_auc_score(y_true, predictions)

print("Sensitivity: {:.2f}".format(sensitivity))
print("Specificity: {:.2f}".format(specificity))
print("ROC-AUC Score: {:.2f}".format(roc_auc))

